```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
import joblib

class EnhancedDataDetectiveAI:
    """
    A class for data investigation and prediction using machine learning models.
    """
    def __init__(self, data_source):
        self.data_source = data_source
        self.model = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None

    def load_data(self):
        # Load the dataset
        data = pd.read_csv(self.data_source)
        return data

    def preprocess_data(self, data, target_column, test_size=0.2, random_state=42):
        # Split the data into features and target
        X = data.drop(target_column, axis=1)
        y = data[target_column]

        # Split the dataset into training and testing sets
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state
        )

    def train_model(self):
        """
        Train the model using a pipeline that standardizes the data and creates a model.
        """
        # Create a pipeline that standardizes the data then creates a model
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('classifier', RandomForestClassifier(random_state=42))
        ])

        # Train the model
        pipeline.fit(self.X_train, self.y_train)
        self.model = pipeline

    def evaluate_model(self):
        """
        Evaluate the model.
        
        Returns:
            tuple: The classification report and accuracy score.
        """
        # Predictions
        predictions = self.model.predict(self.X_test)

        # Evaluation
        report = classification_report(self.y_test, predictions)
        accuracy = accuracy_score(self.y_test, predictions)

        return report, accuracy

    def save_model(self, file_path):
        """
        Save the trained model for later use.
        
        Args:
            file_path (str): The file path to save the model.
        """
        # Save the trained model for later use
        joblib.dump(self.model, file_path)

    def load_model(self, file_path):
        # Load a pre-trained model
        self.model = joblib.load(file_path)

    def predict(self, new_data):
        """
        Make predictions on new data.
        
        Args:
            new_data: The new data to make predictions on.
        
        Returns:
            array: Predicted classes.
        """
        # Make predictions on new data
        return self.model.predict(new_data)

# Example usage:
# data_detective = DataDetectiveAI('path_to_dataset.csv')
# data = data_detective.load_data()
# data_detective.preprocess_data(data, 'target_column_name')
# data_detective.train_model()
# report, accuracy = data_detective.evaluate_model()
# print(report)
# print(f"Model accuracy: {accuracy}")
# data_detective.save_model('data_detective_model.pkl')
```

This code defines a `DataDetectiveAI` class that can be used to load a dataset, preprocess it, train a Random Forest classifier model, evaluate the model, and save it for later use. It also includes methods to load a pre-trained model and make predictions on new data. The example usage at the end demonstrates how to instantiate the class, train the model, and evaluate its performance.